# üîß Troubleshooting - Federated Learning LSTM

## üö® Problemas Comuns e Solu√ß√µes

### 1. Erro de Dimens√£o (RuntimeError)

#### Erro:
```
RuntimeError: The size of tensor a (10) must match the size of tensor b (200) at non-singleton dimension 1
```

#### Causa:
O `prediction-length` no modelo n√£o corresponde ao tamanho dos labels gerados pelos dados.

#### Solu√ß√£o:
```toml
# Em pyproject.toml, certifique-se de que:
[tool.flwr.app.config]
prediction-length = 10  # Deve ser consistente em todo o projeto
```

#### Como verificar:
```bash
python test_config.py
```

---

### 2. Dados Insuficientes

#### Erro:
```
ValueError: A divis√£o de dados para o cliente X resultou em um conjunto vazio.
```

#### Causa:
O arquivo CSV n√£o tem linhas suficientes para criar janelas deslizantes.

#### F√≥rmula:
```
M√≠nimo de linhas = sequence_length + prediction_length
```

Exemplo com configura√ß√£o padr√£o:
```
60 (sequence) + 10 (prediction) = 70 linhas m√≠nimas
```

#### Solu√ß√£o:
1. Adicione mais dados aos CSVs
2. OU reduza `sequence-length`:
```toml
sequence-length = 30  # Reduzido de 60
```

---

### 3. N√≥s Insuficientes

#### Erro:
```
INFO: Waiting for at least 3 nodes to connect...
```

#### Causa:
Menos SuperNodes conectados que o m√≠nimo especificado.

#### Solu√ß√£o:
1. Inicie mais SuperNodes:
```bash
# Terminal adicional
flower-supernode --insecure --superlink 127.0.0.1:9092 \
  --clientappio-api-address 127.0.0.1:9097 \
  --node-config "partition-id=3"
```

2. OU reduza `min-nodes`:
```toml
min-nodes = 2  # Reduzido de 3
```

---

### 4. Perda Muito Alta / N√£o Converge

#### Sintoma:
```
Loss inicial: 15.234567
Loss final: 15.198765
Melhoria: 0.23%
```

#### Poss√≠veis Causas:

**A. Learning Rate muito baixo**
```toml
learning-rate = 1e-4  # Aumentar de 1e-5
```

**B. Poucos rounds**
```toml
rounds = 20  # Aumentar de 5
```

**C. Modelo muito simples**
```toml
hidden-size = 100  # Aumentar de 50
num-layers = 2     # Aumentar de 1
```

**D. Batch size inadequado**
```toml
batch-size = 64  # Ajustar de 32
```

---

### 5. Overfitting

#### Sintoma:
```
Loss de treino: 0.05 (muito baixo)
Loss de valida√ß√£o: 2.35 (muito alto)
```

#### Solu√ß√µes:

**A. Reduzir epochs locais**
```toml
local-epochs = 1  # Reduzir de 2 ou 3
```

**B. Aumentar regulariza√ß√£o (gradient clipping)**
```toml
max-grad-norm = 0.5  # Reduzir de 1.0
```

**C. Aumentar dados de treino**
```toml
train-test-split = 0.9  # Aumentar de 0.8
```

---

### 6. Out of Memory (OOM)

#### Erro:
```
RuntimeError: CUDA out of memory
```

#### Solu√ß√µes em ordem de prefer√™ncia:

**A. Reduzir batch size**
```toml
batch-size = 16  # Reduzir de 32
```

**B. Reduzir tamanho do modelo**
```toml
hidden-size = 32  # Reduzir de 50
num-layers = 1    # Manter m√≠nimo
```

**C. Reduzir sequence length**
```toml
sequence-length = 30  # Reduzir de 60
```

**D. Usar CPU**
```python
# O c√≥digo j√° detecta automaticamente, mas for√ßa CPU:
DEVICE = torch.device("cpu")
```

---

### 7. Estrat√©gia N√£o Encontrada

#### Erro:
```
KeyError: 'fedadam'
```

#### Causa:
Nome da estrat√©gia incorreto ou n√£o suportado.

#### Estrat√©gias dispon√≠veis:
```toml
strategy = "fedavg"      # ‚úÖ FedAvg (padr√£o)
strategy = "fedadam"     # ‚úÖ FedAdam
strategy = "fedyogi"     # ‚úÖ FedYogi
strategy = "fedadagrad"  # ‚úÖ FedAdagrad
```

---

### 8. Arquivo CSV com Colunas Faltando

#### Erro:
```
KeyError: 'vehicle_speed'
```

#### Causa:
CSV n√£o cont√©m todas as colunas necess√°rias.

#### Colunas obrigat√≥rias:
- `vehicle_speed`
- `engine_rpm`
- `accel_x`
- `accel_y`
- `P_kW`
- `dt`

#### Verificar:
```python
import pandas as pd
df = pd.read_csv("data/client_0/route1.csv")
print(df.columns.tolist())
```

---

### 9. Problemas com Certificados TLS

#### Erro:
```
SSL: CERTIFICATE_VERIFY_FAILED
```

#### Causa:
Certificados inv√°lidos ou path incorreto.

#### Solu√ß√£o tempor√°ria (apenas desenvolvimento):
```toml
[tool.flwr.federations.raspberry-deployment]
address = "127.0.0.1:9093"
insecure = true  # ‚ö†Ô∏è Apenas para desenvolvimento!
```

#### Solu√ß√£o para produ√ß√£o:
Veja o guia oficial: [Enable TLS connections](https://flower.ai/docs/framework/how-to-enable-tls-connections.html)

---

### 10. SuperNode Desconecta Durante Treinamento

#### Sintoma:
```
INFO: Received 2 results and 1 failures
```

#### Causas Poss√≠veis:

**A. Timeout muito curto**

Adicione no `server.py`:
```python
result = strategy.start(
    grid=grid,
    initial_arrays=initial_arrays,
    num_rounds=num_rounds,
    timeout=7200,  # Aumentar para 2 horas
)
```

**B. Dados corrompidos em um cliente**

Execute o teste:
```bash
python test_config.py
```

**C. Mem√≥ria insuficiente**

Reduza `batch-size` ou `hidden-size`.

---

### 11. Gr√°ficos Vazios / Sem Dados

#### Sintoma:
PDFs gerados mas com mensagem "Dados insuficientes"

#### Causa:
Todos os clientes falharam ou estrat√©gia n√£o agregou resultados.

#### Verificar logs:
```bash
# Procure por:
INFO: aggregate_train: Received 0 results and 3 failures
```

#### Solu√ß√£o:
1. Verifique se todos os clientes t√™m dados v√°lidos
2. Execute `python test_config.py` para cada cliente

---

### 12. Configura√ß√£o N√£o Aplicada

#### Sintoma:
Alterou `pyproject.toml` mas valores antigos ainda s√£o usados.

#### Causa:
Configura√ß√µes sendo sobrescritas via linha de comando.

#### Verificar:
```bash
# N√ÉO use --run-config se quer usar pyproject.toml
flwr run .  # ‚úÖ Correto

# Isso sobrescreve pyproject.toml:
flwr run . --run-config "rounds=10"  # ‚ö†Ô∏è Sobrescreve
```

---

### 13. Erro ao Importar M√≥dulos

#### Erro:
```
ModuleNotFoundError: No module named 'utils'
```

#### Solu√ß√£o:
```bash
# Certifique-se de estar no diret√≥rio correto
cd /caminho/para/seu/projeto

# Reinstale o projeto
pip install -e .
```

---

### 14. Diverg√™ncia entre Clientes

#### Sintoma:
```
Desvio padr√£o final entre clientes: 5.432100
Converg√™ncia: Baixa
```

#### Causas e Solu√ß√µes:

**A. Dados muito heterog√™neos**
- Isso √© esperado em FL! 
- Considere usar mais rounds:
```toml
rounds = 20  # Aumentar
```

**B. Learning rate muito alto**
```toml
learning-rate = 5e-6  # Reduzir de 1e-5
```

**C. Clientes com quantidade muito diferente de dados**
- Verifique a distribui√ß√£o:
```bash
python test_config.py
```

---

## üîç Diagn√≥stico Sistem√°tico

### Passo 1: Validar Configura√ß√£o
```bash
python test_config.py
```

### Passo 2: Verificar Estrutura de Dados
```bash
ls -la data/client_*/
```

### Passo 3: Testar Modelo Isoladamente
```python
from utils import Net, load_data
import torch

# Teste b√°sico
trainloader, testloader, num_features = load_data(0, 60, 10, 32, 0.8)
net = Net(num_features, 50, 10)

for sequences, labels in trainloader:
    outputs = net(sequences)
    print(f"Input: {sequences.shape}, Output: {outputs.shape}, Labels: {labels.shape}")
    break
```

### Passo 4: Verificar Logs
```bash
# Procure por padr√µes:
grep "ERROR" logfile.txt
grep "RuntimeError" logfile.txt
grep "failure" logfile.txt
```

---

## üìä M√©tricas de Refer√™ncia

### Boas M√©tricas de Treinamento

```
‚úÖ Loss de treino diminuindo: 2.5 ‚Üí 0.8 ‚Üí 0.3 ‚Üí 0.15
‚úÖ Loss de valida√ß√£o diminuindo: 2.8 ‚Üí 1.2 ‚Üí 0.5 ‚Üí 0.25
‚úÖ Converg√™ncia boa: Desvio padr√£o < 0.05
‚úÖ Melhoria > 60% ap√≥s 10 rounds
```

### M√©tricas Problem√°ticas

```
‚ùå Loss estagnado: 2.5 ‚Üí 2.48 ‚Üí 2.47 ‚Üí 2.46
‚ùå Overfitting: Train=0.05, Val=2.5
‚ùå Converg√™ncia baixa: Desvio padr√£o > 1.0
‚ùå Melhoria < 10% ap√≥s 10 rounds
```

---

## üõ†Ô∏è Ferramentas de Debug

### 1. Modo Verbose
```python
# Em utils.py, adicione prints:
def train(net, trainloader, epochs, learning_rate, max_grad_norm, device):
    print(f"[DEBUG] Training with LR={learning_rate}, Epochs={epochs}")
    # ...
```

### 2. Checkpoint de Debug
```python
# Salve modelo a cada round para inspecionar:
save-checkpoint-every = 1  # Salvar sempre
```

### 3. Visualizar Gradientes
```python
# Adicione ao loop de treino:
for name, param in net.named_parameters():
    if param.grad is not None:
        print(f"{name}: grad_norm={param.grad.norm().item():.6f}")
```

---

## üìû Obtendo Ajuda

### 1. Issues do GitHub
Se o problema persistir, abra uma issue em:
- [Flower GitHub Issues](https://github.com/adap/flower/issues)

### 2. Documenta√ß√£o Oficial
- [Flower Docs](https://flower.ai/docs/)
- [PyTorch LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)

### 3. F√≥rum Flower
- [Flower Discuss](https://discuss.flower.ai/)

---

## ‚úÖ Checklist Pr√©-Execu√ß√£o

Antes de rodar `flwr run .`, verifique:

- [ ] `python test_config.py` passou todos os testes
- [ ] Dados existem em `data/client_0/`, `data/client_1/`, etc.
- [ ] CSVs t√™m todas as colunas necess√°rias
- [ ] `prediction-length` est√° correto no `pyproject.toml`
- [ ] N√∫mero de SuperNodes >= `min-nodes`
- [ ] Espa√ßo em disco suficiente para checkpoints
- [ ] Mem√≥ria RAM/GPU suficiente para o batch-size escolhido

---

## üéØ Configura√ß√µes Recomendadas por Cen√°rio

### Teste R√°pido (2-3 minutos)
```toml
rounds = 3
sequence-length = 30
prediction-length = 5
batch-size = 64
local-epochs = 1
```

### Desenvolvimento (10-15 minutos)
```toml
rounds = 10
sequence-length = 60
prediction-length = 10
batch-size = 32
local-epochs = 1
```

### Produ√ß√£o (1-2 horas)
```toml
rounds = 50
sequence-length = 120
prediction-length = 20
batch-size = 32
local-epochs = 2
hidden-size = 100
num-layers = 2
```

### GPU Limitada
```toml
batch-size = 16
hidden-size = 32
sequence-length = 30
num-layers = 1
```

### CPU Only (mais lento)
```toml
batch-size = 8
hidden-size = 32
sequence-length = 30
local-epochs = 1
```

---

## üìù Log de Mudan√ßas nas Configura√ß√µes

Mantenha um hist√≥rico das suas configura√ß√µes:

```toml
# Em pyproject.toml, adicione coment√°rios:
[tool.flwr.app.config]
# Experimento 1 (2025-01-08): Baseline
# rounds = 5, hidden-size = 50
# Resultado: Loss=0.45

# Experimento 2 (2025-01-09): Aumentar capacidade
# rounds = 10, hidden-size = 100
# Resultado: Loss=0.32 (melhoria de 28%)

# Configura√ß√£o atual:
rounds = 10
hidden-size = 100
```

---

## üîÑ Workflow de Debugging Recomendado

1. **Execute teste de configura√ß√£o**
   ```bash
   python test_config.py
   ```

2. **Rode com poucos rounds primeiro**
   ```toml
   rounds = 2
   ```

3. **Verifique logs cuidadosamente**
   - Procure por erros
   - Verifique se todos os clientes participaram
   - Confirme que agrega√ß√£o funcionou

4. **Se funcionou, aumente gradualmente**
   ```toml
   rounds = 5  # Depois 10, 20, etc.
   ```

5. **Monitore recursos do sistema**
   ```bash
   # Linux/Mac
   htop
   
   # Windows
   Gerenciador de Tarefas
   ```

6. **Salve configura√ß√µes bem-sucedidas**
   - Fa√ßa commit do `pyproject.toml`
   - Documente no README ou comments

---

**Lembre-se**: A maioria dos problemas vem de incompatibilidade entre `prediction-length` e os dados. Execute `python test_config.py` sempre que mudar configura√ß√µes!