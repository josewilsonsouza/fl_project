# Federated Learning para PrevisÃ£o de Consumo de CombustÃ­vel

Sistema de Aprendizado Federado (FL) para prever consumo de combustÃ­vel usando dados de sensores OBD de diferentes veÃ­culos, mantendo a privacidade dos dados em cada cliente.

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um sistema de Aprendizado Federado usando o framework Flower, onde:
- **3 clientes** (Ubuntu) representam diferentes veÃ­culos com seus dados locais
- **1 servidor** (Windows) coordena o treinamento sem acessar os dados brutos
- Modelo LSTM para previsÃ£o de sÃ©ries temporais de consumo (P_kW)
- MÃºltiplas estratÃ©gias de agregaÃ§Ã£o: FedAvg, FedAdam, FedYogi, FedAdagrad

## ğŸ—ï¸ Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Servidor (Win) â”‚
â”‚   16GB RAM      â”‚
â”‚   Porta: 8080   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”
â”‚Clienteâ”‚ â”‚Clienteâ”‚ â”‚Cliente â”‚
â”‚   1   â”‚ â”‚   2  â”‚ â”‚   3    â”‚
â”‚Ubuntu â”‚ â”‚Ubuntuâ”‚ â”‚Ubuntu  â”‚
â”‚ 8GB   â”‚ â”‚ 8GB  â”‚ â”‚  8GB   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estrutura do Projeto

```
fl_project/
â”œâ”€â”€ data/                    # Dados dos veÃ­culos (nÃ£o versionado)
â”‚   â”œâ”€â”€ client_1/           # Percursos do veÃ­culo 1
â”‚   â”‚   â”œâ”€â”€ percurso_1.csv
â”‚   â”‚   â”œâ”€â”€ percurso_2.csv
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ client_2/           # Percursos do veÃ­culo 2
â”‚   â””â”€â”€ client_3/           # Percursos do veÃ­culo 3
â”œâ”€â”€ server.py               # CÃ³digo do servidor FL
â”œâ”€â”€ client.py               # CÃ³digo dos clientes FL
â”œâ”€â”€ utils.py                # Modelo LSTM e funÃ§Ãµes auxiliares
â”œâ”€â”€ analysis_tool.py        # Ferramenta de anÃ¡lise pÃ³s-treinamento
â”œâ”€â”€ run.sh                  # Script para execuÃ§Ã£o local
â”œâ”€â”€ run_all_strategies.sh   # Script para testar todas as estratÃ©gias
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â””â”€â”€ README.md              # Este arquivo
```

## ğŸ”§ Requisitos do Sistema

### Hardware MÃ­nimo
- **Servidor**: 8GB RAM (recomendado 16GB)
- **Clientes**: 4GB RAM cada (recomendado 8GB)
- **Rede**: ConexÃ£o estÃ¡vel entre servidor e clientes

### Software
- **Python**: 3.10 - 3.11
- **Sistema Operacional**:
  - Servidor: Windows 10/11 ou Linux
  - Clientes: Ubuntu 20.04/22.04

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/seu-usuario/fl_project.git
cd fl_project
```

### 2. Crie um Ambiente Virtual

**No Ubuntu (Clientes):**
```bash
python3 -m venv venv
source venv/bin/activate
```

**No Windows (Servidor):**
```powershell
python -m venv venv
.\venv\Scripts\activate
```

### 3. Instale as DependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Prepare os Dados

Organize os dados de cada veÃ­culo na estrutura:
```
data/
â”œâ”€â”€ client_1/  # Dados do veÃ­culo 1
â”œâ”€â”€ client_2/  # Dados do veÃ­culo 2
â””â”€â”€ client_3/  # Dados do veÃ­culo 3
```

**Formato esperado dos CSVs:**
- Colunas principais: `vehicle_speed`, `engine_rpm`, `accel_x`, `accel_y`, `P_kW`, `dt`
- Cada arquivo representa um percurso diferente
- MÃ­nimo de 2 percursos por cliente recomendado

## ğŸš€ ExecuÃ§Ã£o em Ambiente DistribuÃ­do

### ConfiguraÃ§Ã£o de Rede

1. **Identifique o IP do servidor Windows:**
   ```powershell
   ipconfig
   ```
   Procure pelo IPv4 Address (ex: 192.168.1.100)

2. **Teste a conectividade dos clientes Ubuntu:**
   ```bash
   ping 192.168.1.100
   ```

### Passo 1: Iniciar o Servidor (Windows)

```powershell
# Ative o ambiente virtual
.\venv\Scripts\activate

# Execute o servidor
python server.py --strategy fedavg --rounds 15

# Ou com parÃ¢metros customizados
python server.py --strategy fedadam --rounds 20 --min-clients 3
```

O servidor iniciarÃ¡ na porta 8080 e aguardarÃ¡ a conexÃ£o dos clientes.

### Passo 2: Iniciar os Clientes (Ubuntu)

**Em cada mÃ¡quina Ubuntu, execute em terminais separados:**

**Cliente 1:**
```bash
# Ative o ambiente virtual
source venv/bin/activate

# Execute o cliente 1
python client.py --client-id 1 --server-address 192.168.1.100:8080 --prediction-length 10
```

**Cliente 2:**
```bash
source venv/bin/activate
python client.py --client-id 2 --server-address 192.168.1.100:8080 --prediction-length 10
```

**Cliente 3:**
```bash
source venv/bin/activate
python client.py --client-id 3 --server-address 192.168.1.100:8080 --prediction-length 10
```

### Monitoramento

O progresso serÃ¡ exibido em tempo real:
- **Servidor**: Mostra rodadas completas e mÃ©tricas globais
- **Clientes**: Exibem perdas locais de treino/validaÃ§Ã£o

## ğŸ“Š AnÃ¡lise dos Resultados

### ApÃ³s o Treinamento

1. **Executar anÃ¡lise automÃ¡tica:**
   ```bash
   python analysis_tool.py --results-dir results
   ```

2. **VisualizaÃ§Ãµes geradas (PDFs):**
   - `performance_analysis_*.pdf`: AnÃ¡lise de desempenho completa
   - `convergence_analysis_*.pdf`: MÃ©tricas de convergÃªncia
   - `heatmap_performance_*.pdf`: Mapa de calor temporal
   - `comparative_analysis.pdf`: ComparaÃ§Ã£o entre estratÃ©gias
   - `client_evolution_analysis.pdf`: EvoluÃ§Ã£o individual

3. **MÃ©tricas salvas:**
   - `results/detailed_metrics_*.csv`: Dados completos
   - `results/summary_report.json`: RelatÃ³rio consolidado
   - `metrics/client_*/metrics_history.json`: HistÃ³rico por cliente

## ğŸ”¬ EstratÃ©gias de AgregaÃ§Ã£o

| EstratÃ©gia | DescriÃ§Ã£o | Quando Usar |
|------------|-----------|-------------|
| **FedAvg** | MÃ©dia ponderada simples | Dados homogÃªneos |
| **FedAdam** | OtimizaÃ§Ã£o adaptativa | ConvergÃªncia mais rÃ¡pida |
| **FedYogi** | Adam com controle de variÃ¢ncia | Dados heterogÃªneos |
| **FedAdagrad** | Taxa de aprendizado adaptativa | Dados esparsos |

### Comparar Todas as EstratÃ©gias

```bash
# Linux/Ubuntu
chmod +x run_all_strategies.sh
./run_all_strategies.sh 15 10

# Windows (usando Git Bash ou WSL)
bash run_all_strategies.sh 15 10
```

## ğŸ› ï¸ Troubleshooting

### Erro de ConexÃ£o

**Problema**: Clientes nÃ£o conseguem conectar ao servidor

**SoluÃ§Ãµes**:
1. Verifique o firewall do Windows:
   ```powershell
   # Permitir porta 8080
   netsh advfirewall firewall add rule name="FL Server" dir=in action=allow protocol=TCP localport=8080
   ```

2. Confirme que o servidor estÃ¡ rodando:
   ```powershell
   netstat -an | findstr :8080
   ```

### Erro de MemÃ³ria

**Problema**: Out of Memory durante treinamento

**SoluÃ§Ãµes**:
1. Reduza o batch_size em `utils.py`
2. Diminua sequence_length ou prediction_length
3. Use menos Ã©pocas por rodada

### Dados Insuficientes

**Problema**: "conjunto de treino ou teste vazio"

**SoluÃ§Ãµes**:
1. Verifique se hÃ¡ dados suficientes em `data/client_X/`
2. Ajuste sequence_length e prediction_length
3. Confirme que os CSVs tÃªm as colunas esperadas

## ğŸ“ˆ ParÃ¢metros Importantes

### Server.py
- `--strategy`: EstratÃ©gia de agregaÃ§Ã£o (fedavg, fedadam, etc.)
- `--rounds`: NÃºmero de rodadas de FL (default: 10)
- `--min-clients`: Clientes mÃ­nimos para iniciar (default: 3)

### Client.py
- `--client-id`: ID do cliente (1, 2 ou 3)
- `--server-address`: EndereÃ§o IP:porta do servidor
- `--prediction-length`: Passos futuros a prever (default: 10)

### Utils.py (configuraÃ§Ãµes internas)
- `sequence_length`: Janela de entrada (default: 60)
- `batch_size`: Tamanho do batch (default: 32)
- `learning_rate`: Taxa de aprendizado (default: 1e-5)

## ğŸ“ Notas de Desenvolvimento

### Modelo LSTM
- Entrada: 6 features (velocidade, RPM, aceleraÃ§Ãµes, consumo, tempo)
- Hidden size: 50 neurÃ´nios
- SaÃ­da: PrevisÃ£o de N passos futuros de consumo (P_kW)

### DivisÃ£o dos Dados
- 80% para treinamento
- 20% para validaÃ§Ã£o
- NormalizaÃ§Ã£o MinMaxScaler por cliente

### MÃ©tricas
- Loss: MSE (Mean Squared Error)
- AvaliaÃ§Ã£o: Por cliente e global
- ConvergÃªncia: VariÃ¢ncia entre clientes

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie sua feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

DistribuÃ­do sob a licenÃ§a MIT. Veja `LICENSE` para mais informaÃ§Ãµes.

## ğŸ‘¥ Autores

- JosÃ© Wilson C. Souza
- Erick Andrade Borba
- JoÃ£o Alfredo Cal Braz

## ğŸ™ Agradecimentos

- [Flower Framework](https://flower.dev/) - Framework de Aprendizado Federado
- [PyTorch](https://pytorch.org/) - Framework de Deep Learning
- Dados coletados via OBD Link

---
